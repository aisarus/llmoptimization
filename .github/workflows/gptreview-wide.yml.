  name: GPTReview Wide

on:
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  contents: read
  pull-requests: write
  security-events: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  review:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Build minimal checker (scan only added lines)
        env:
          BASE_REF: ${{ github.base_ref }}
        run: |
          python3 - <<'PY'
          import json, re, subprocess, os
          from pathlib import Path

          base = os.environ.get("BASE_REF","")
          if base:
              subprocess.run(["git","fetch","origin",base], check=False)

          # Unified diff with zero context -> точные номера добавленных строк
          diff = subprocess.check_output(
              ["git","diff","--unified=0", f"origin/{base}", "HEAD"],
              text=True, stderr=subprocess.STDOUT
          )

          findings=[]
          rules_meta={
            "py_eval_exec": {"severity":"critical","msg":"avoid eval/exec","lang":"py"},
            "py_except_pass": {"severity":"major","msg":"bare except pass","lang":"py"},
            "py_print_debug": {"severity":"minor","msg":"debug prints","lang":"py"},
            "js_innerHTML": {"severity":"critical","msg":"assignment to innerHTML (XSS risk)","lang":"js"},
            "js_console_log": {"severity":"minor","msg":"console.log left in code","lang":"js"},
          }

          cur_file=None; line_no=0
          hunk_re=re.compile(r"^@@ -\d+(?:,\d+)? \+(\d+)(?:,(\d+))? @@")
          add_py=re.compile(r".*\.py$")
          add_js=re.compile(r".*\.(?:js|ts|jsx|tsx)$")

          for raw in diff.splitlines():
              if raw.startswith("+++ b/"):
                  cur_file=raw[6:]
              elif raw.startswith("@@"):
                  m=hunk_re.match(raw)
                  if m:
                      line_no=int(m.group(1))
              elif raw.startswith("+") and not raw.startswith("+++"):
                  code=raw[1:]
                  lang="py" if add_py.match(cur_file or "") else ("js" if add_js.match(cur_file or "") else None)
                  if not lang: 
                      line_no += 1; 
                      continue

                  def add(rule):
                      meta=rules_meta[rule]
                      findings.append({
                        "path":cur_file,"line":line_no,"rule":rule,
                        "severity":meta["severity"],"msg":meta["msg"]
                      })

                  if lang=="py":
                      if re.search(r"\b(eval|exec)\s*\(", code): add("py_eval_exec")
                      if re.search(r"except\s*:\s*pass", code): add("py_except_pass")
                      if re.search(r"\bprint\s*\(", code): add("py_print_debug")
                  else:
                      if re.search(r"\.innerHTML\s*=", code): add("js_innerHTML")
                      if re.search(r"\bconsole\.log\s*\(", code): add("js_console_log")

                  line_no += 1
              else:
                  # context/removed — не увеличиваем line_no
                  pass

          # де-дуп на всякий случай
          seen=set(); dedup=[]
          for f in findings:
              key=(f["path"],f["line"],f["rule"])
              if key in seen: 
                  continue
              seen.add(key); dedup.append(f)
          findings=dedup

          summary={"criticals":0,"majors":0,"minors":0}
          for f in findings:
              s=f["severity"]
              if s=="critical": summary["criticals"]+=1
              elif s=="major": summary["majors"]+=1
              elif s=="minor": summary["minors"]+=1

          Path("findings.json").write_text(json.dumps(findings,ensure_ascii=False))
          Path("gptreview_report.json").write_text(json.dumps({"summary":summary},ensure_ascii=False))

          # SARIF 2.1.0
          rules={}
          for f in findings:
              if f["rule"] not in rules:
                  rules[f["rule"]]={"id":f["rule"],"name":f["rule"],"shortDescription":{"text":f["msg"]},"help":{"text":f["msg"]}}
          sarif={
            "version":"2.1.0",
            "$schema":"https://json.schemastore.org/sarif-2.1.0.json",
            "runs":[{"tool":{"driver":{"name":"GPTReview Wide","rules":list(rules.values())}},
                     "results":[{"ruleId":f["rule"],
                                 "level":"error" if f["severity"]=="critical" else ("warning" if f["severity"]=="major" else "note"),
                                 "message":{"text":f["msg"]},
                                 "locations":[{"physicalLocation":{"artifactLocation":{"uri":f["path"]},
                                                                      "region":{"startLine":f["line"]}}}]} for f in findings]}]
          }
          Path("results.sarif").write_text(json.dumps(sarif))
          PY

      - name: Upload SARIF (Code scanning)
        uses: github/codeql-action/upload-sarif@v3
        with: { sarif_file: results.sarif }

      - name: Upsert summary comment
        uses: actions/github-script@v7
        with:
          script: |
            const marker = "<!-- GPTREVIEW_SUMMARY -->";
            const fs = require('fs');
            const rep = JSON.parse(fs.readFileSync('gptreview_report.json','utf8'));
            const s = rep.summary || {criticals:0,majors:0,minors:0};
            const body = `${marker}\n**GPTReview Wide** — criticals: ${s.criticals}, majors: ${s.majors}, minors: ${s.minors}`;
            const {owner, repo} = context.repo;
            const issue_number = context.payload.pull_request.number;
            const all = await github.paginate(github.rest.issues.listComments,{owner,repo,issue_number});
            const mine = all.find(c => c.body && c.body.includes(marker));
            if (mine) {
              await github.rest.issues.updateComment({owner,repo,comment_id: mine.id, body});
            } else {
              await github.rest.issues.createComment({owner,repo,issue_number,body});
            }

      - name: Post line comments (up to 25)
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const findings = JSON.parse(fs.readFileSync('findings.json','utf8'));
            const pr = context.payload.pull_request;
            const comments = findings.slice(0,25).map(f => ({
              path: f.path,
              line: f.line,
              side: 'RIGHT',
              body: `${f.msg}  \nSeverity: **${f.severity}**  \nRule: \`${f.rule}\``
            }));
            if (comments.length) {
              await github.rest.pulls.createReview({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: pr.number,
                event: 'COMMENT',
                comments
              });
            }
